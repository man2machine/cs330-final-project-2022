{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from cs330_project.datasets.video_data import TinyVIRAT\n",
    "from cs330_project.models import ViTAutoEncoder, ViTClassifier\n",
    "from cs330_project.datasets.data_loading import MaskedVideoAutoencoderTransform, VideoAugmentTransform, TransformDataset, DataLoader\n",
    "from cs330_project.training import train_classifier_model, make_optimizer, make_scheduler\n",
    "from cs330_project.utils import get_rel_pkg_path\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (32, 32)\n",
    "num_frames = 16\n",
    "num_channels = 3\n",
    "patch_size = 8\n",
    "tubelet_size = 4\n",
    "sampling_rate = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = r\"D:\\tiny_virat_composite_dataset\"\n",
    "root_dir = r\"C:\\Users\\Windows\\Desktop\\Shahir\\cs330-final-project-2022\\resources\\tiny_virat_processed\"\n",
    "dataset_train_orig = TinyVIRAT(\n",
    "    root_dir=root_dir,\n",
    "    train=True,\n",
    "    new_length=num_frames,\n",
    "    new_step=sampling_rate,\n",
    "    temporal_jitter=False,\n",
    "    verbose=False)\n",
    "dataset_test_orig = TinyVIRAT(\n",
    "    root_dir=root_dir,\n",
    "    train=False,\n",
    "    new_length=num_frames,\n",
    "    new_step=sampling_rate,\n",
    "    temporal_jitter=False,\n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_fname = \"C:\\\\Users\\\\Windows\\\\Desktop\\\\Shahir\\\\cs330-final-project-2022\\\\weights\\\\Experiment 12-13-2022 01-33-21 AM\\\\Weights Latest.pckl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ViTAutoEncoder:\n\tMissing key(s) in state_dict: \"mask_token\", \"decoder.mask_token\". \n\tsize mismatch for decoder.pos_embedding: copying a param with shape torch.Size([1, 65, 48]) from checkpoint, the shape in current model is torch.Size([1, 66, 48]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 21\u001b[0m\n\u001b[0;32m      1\u001b[0m vmae_model \u001b[38;5;241m=\u001b[39m ViTAutoEncoder(\n\u001b[0;32m      2\u001b[0m     in_img_size\u001b[38;5;241m=\u001b[39mimg_size,\n\u001b[0;32m      3\u001b[0m     in_channels\u001b[38;5;241m=\u001b[39mnum_channels,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     is_lsa\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     19\u001b[0m     use_masking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m vmae_model \u001b[38;5;241m=\u001b[39m vmae_model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mvmae_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_fname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cs330-final-project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1667\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1662\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   1663\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1664\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   1666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1668\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   1669\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ViTAutoEncoder:\n\tMissing key(s) in state_dict: \"mask_token\", \"decoder.mask_token\". \n\tsize mismatch for decoder.pos_embedding: copying a param with shape torch.Size([1, 65, 48]) from checkpoint, the shape in current model is torch.Size([1, 66, 48])."
     ]
    }
   ],
   "source": [
    "vmae_model = ViTAutoEncoder(\n",
    "    in_img_size=img_size,\n",
    "    in_channels=num_channels,\n",
    "    patch_size=patch_size,\n",
    "    spatio_temporal=True,\n",
    "    tubelet_size=tubelet_size,\n",
    "    in_num_frames=num_frames,\n",
    "    encoder_embed_dim=96,\n",
    "    encoder_depth=6,\n",
    "    encoder_num_heads=8,\n",
    "    decoder_embed_dim=48,\n",
    "    decoder_depth=3,\n",
    "    decoder_num_heads=8,\n",
    "    mlp_dim_ratio=2,\n",
    "    head_dim=16,\n",
    "    class_embed=True,\n",
    "    is_spt=True,\n",
    "    is_lsa=False,\n",
    "    use_masking=True)\n",
    "vmae_model = vmae_model.to(device)\n",
    "vmae_model.load_state_dict(torch.load(weights_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViTClassifier(\n",
    "    in_img_size=img_size,\n",
    "    in_channels=num_channels,\n",
    "    patch_size=patch_size,\n",
    "    spatio_temporal=True,\n",
    "    tubelet_size=tubelet_size,\n",
    "    num_classes=26,\n",
    "    in_num_frames=num_frames,\n",
    "    encoder_embed_dim=96,\n",
    "    encoder_depth=6,\n",
    "    encoder_num_heads=8,\n",
    "    mlp_dim_ratio=2,\n",
    "    head_dim=16,\n",
    "    class_embed=True,\n",
    "    is_spt=True,\n",
    "    is_lsa=False,\n",
    "    use_masking=True)\n",
    "model = model.to(device)\n",
    "model.encoder.load_state_dict(vmae_model.encoder.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = MaskedVideoAutoencoderTransform(\n",
    "    input_size=img_size,\n",
    "    num_patches=model.encoder.num_patches,\n",
    "    mask_ratio=0.0)\n",
    "test_transform = MaskedVideoAutoencoderTransform(\n",
    "    input_size=img_size,\n",
    "    num_patches=model.encoder.num_patches,\n",
    "    crop_type=VideoAugmentTransform.CROP_TYPE_CENTER,\n",
    "    mask_ratio=0.0)\n",
    "dataset_train = TransformDataset(\n",
    "    dataset_train_orig,\n",
    "    labeled=True,\n",
    "    transform_func=train_transform)\n",
    "dataset_test = TransformDataset(\n",
    "    dataset_test_orig,\n",
    "    labeled=True,\n",
    "    transform_func=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = make_optimizer(model)\n",
    "scheduler = make_scheduler(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=20,\n",
    "    num_workers=20,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=10,\n",
    "    persistent_workers=True)\n",
    "dataloader_test = DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=20,\n",
    "    num_workers=20,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=10,\n",
    "    persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dir = get_rel_pkg_path(\"weights/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = train_classifier_model(\n",
    "    device,\n",
    "    model,\n",
    "    dataloader_train,\n",
    "    dataloader_test,\n",
    "    nn.CrossEntropyLoss(),\n",
    "    optimizer,\n",
    "    weights_dir,\n",
    "    num_epochs=10,\n",
    "    save_model=True,\n",
    "    save_latest=True,\n",
    "    save_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dataloader_train:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e83531ffe832af231b72d96521b01eb96431da7f22dd3e704e8115770d7320b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
