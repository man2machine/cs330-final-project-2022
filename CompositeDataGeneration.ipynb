{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b314e2a5-5e9e-480f-a65b-e057d6b49be4",
   "metadata": {},
   "source": [
    "### Small-Scale Composite Dataset Generation\n",
    "\n",
    "We generate a small-scale video dataset consisting of 518 human-action classes with a total of 24,927 videos where each video is a 10 second clip of resolution 64x64 pixels.\n",
    "\n",
    "The following code describes our dataset and annotation generation process. We utilize the [Mini-Kinetics200](https://github.com/s9xie/Mini-Kinetics-200), [Kinetics-400](https://www.kaggle.com/datasets/rohanmallick/kinetics-train-5per?select=kinetics400_5per), and [TinyVIRAT](https://www.crcv.ucf.edu/research/projects/tinyvirat-low-resolution-video-action-recognition/) human-object video datasets to create this composite dataset. \n",
    "\n",
    "In terms of data preprocessing from raw formats, we compile multiple JSON annotation files into a single ```train.json``` and ```test.json``` for our training/testing splits of the composite dataset. Each JSON object in the annotation file is in the following format:\n",
    "\n",
    "```\n",
    "{'id': <numerical ID>,\n",
    " 'video_id': <name of video>,\n",
    " 'path': <filepath in directory>,\n",
    " 'dim': <dimension of a single frame in video (i.e. [64,64])>,\n",
    " 'label': <str label of action class (i.e. \"counting money\")}\n",
    "\n",
    "```\n",
    "\n",
    "For the video data, we utilize ```opencv``` to compress video resolution from native YouTube formats or standardized 224x224 px formats in TinyVIRAT to 64x64 px resolution.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498ea688-b35a-48a5-8729-e4d8062b6786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# TinyVIRAT annotations (raw)\n",
    "\n",
    "f = open(\"tiny_train.json\")\n",
    "train = json.load(f)\n",
    "\n",
    "f = open(\"tiny_test.json\")\n",
    "test = json.load(f)\n",
    "\n",
    "newTrain = train['tubes']\n",
    "newTest = test['tubes']\n",
    "\n",
    "for item in newTrain:\n",
    "    item['label'] = item['label'][0]\n",
    "    item['id'] = str(item['id'])\n",
    "    item['dim'] = [64,64]\n",
    "    \n",
    "for item in newTest:\n",
    "    item['label'] = item['label'][0]\n",
    "    item['id'] = str(item['id'])\n",
    "    item['dim'] = [64,64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f7080955-b711-4716-8d30-52c11743d3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7663"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e640312-a478-4705-a0e7-4f03ca1e23af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Reducing image resolution with OpenCV\n",
    "# https://www.geeksforgeeks.org/how-to-change-video-resolution-in-opencv-in-python/\n",
    "dataPath = \"compositeDataset\"\n",
    "newDim = [64,64]\n",
    "\n",
    "for dirName in os.listdir(dataPath):\n",
    "    subPath = dataPath + \"/\" + dirName\n",
    "    for fname in os.listdir(subPath):\n",
    "        if \".mp4\" in fname:\n",
    "            fPath = subPath + \"/\" + fname\n",
    "            vidcap = cv2.VideoCapture(fPath)\n",
    "            success, image = vidcap.read()\n",
    "            while success:\n",
    "                success, image = vidcap.read()\n",
    "                resize = cv2.resize(image, (newDim[0], newDim[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "68e2cb5a-1718-44a3-85a7-d3a9f1b9c729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kinetics annotations (raw)\n",
    "\n",
    "dataPath = \"kinetics200\"\n",
    "\n",
    "for dirName in os.listdir(dataPath):\n",
    "    subPath = dataPath + \"/\" + dirName\n",
    "    for fname in os.listdir(subPath):\n",
    "        if \".mp4\" in fname:\n",
    "            fPath = subPath + \"/\" + fname\n",
    "            path = dirName + \"/\" + fname\n",
    "            idName = fname.replace(\".mp4\", \"\")\n",
    "            video_id = str(dirName)\n",
    "            label = dirName\n",
    "            \n",
    "            s = dict()\n",
    "            s['id'] = idName\n",
    "            s['video_id'] = video_id\n",
    "            s['path'] = path\n",
    "            s['dim'] = [64,64]\n",
    "            s['label'] = label\n",
    "            \n",
    "            newTrain.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "708bb851-0f24-4620-9a7e-b1879a2c28aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'mBIgVnm995E',\n",
       " 'video_id': 'counting money',\n",
       " 'path': 'counting money/mBIgVnm995E.mp4',\n",
       " 'dim': [64, 64],\n",
       " 'label': 'counting money'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example JSON annotation\n",
    "newTrain[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cf7eb265-66cf-41a9-9752-b1e27f8bde93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24927"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of samples\n",
    "len(newTrain) + len(newTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1052b9e6-f989-49d0-94d9-526854b183f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.json', 'w') as fp:\n",
    "    json.dump(newTrain, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f8f712-6532-4b79-a022-4d4d8d35a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.json', 'w') as fp:\n",
    "    json.dump(newTest, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
